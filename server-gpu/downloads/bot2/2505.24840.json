{
  "status": "success",
  "paper_id": "2505.24840",
  "bot_num": 2,
  "processed_date": "2025-06-04T22:29:03.260068",
  "all_summaries": [
    "The paper investigates the hierarchical visual understanding capabilities of vision large language models (VLLMs), revealing that they lack hierarchical consistency in visual categorization tasks. Key findings include the identification of LLMs as the bottleneck for hierarchical visual understanding, as they fail to retain taxonomy knowledge, while visual encoders and projectors maintain discriminative features. The study constructs six taxonomies and four hierarchical image classification datasets, generating approximately one million four-choice visual question-answering (VQA) tasks to evaluate VLLMs. Results show that VLLMs struggle with hierarchical consistency, with significant gaps between hierarchical consistency (HCA) and leaf-level accuracy (Acc leaf ). Fine-tuning VLLMs on these tasks improves the LLM's hierarchical consistency more than the visual components, affirming the LLM bottleneck. The paper concludes that addressing LLM's lack of taxonomy knowledge is crucial for advancing VLLMs in hierarchical visual understanding.",
    "The paper investigates the hierarchical visual understanding capabilities of vision large language models (VLLMs), revealing that they lack hierarchical consistency, primarily due to the LLM component being the bottleneck. Key findings include that VLLMs fail to maintain hierarchical consistency across taxonomies, with models like Qwen2.5-VL-72B showing over 67% errors in hierarchical paths. LLMs lack taxonomy knowledge, while visual encoders retain discriminative features. Fine-tuning improves LLM's hierarchical consistency more than VLLM's, highlighting LLMs' dominance. The study emphasizes the need to address LLM shortcomings to enhance VLLMs' hierarchical visual understanding."
  ],
  "best_summary_idx": 0,
  "summary": "The paper investigates the hierarchical visual understanding capabilities of vision large language models (VLLMs), revealing that they lack hierarchical consistency in visual categorization tasks. Key findings include the identification of LLMs as the bottleneck for hierarchical visual understanding, as they fail to retain taxonomy knowledge, while visual encoders and projectors maintain discriminative features. The study constructs six taxonomies and four hierarchical image classification datasets, generating approximately one million four-choice visual question-answering (VQA) tasks to evaluate VLLMs. Results show that VLLMs struggle with hierarchical consistency, with significant gaps between hierarchical consistency (HCA) and leaf-level accuracy (Acc leaf ). Fine-tuning VLLMs on these tasks improves the LLM's hierarchical consistency more than the visual components, affirming the LLM bottleneck. The paper concludes that addressing LLM's lack of taxonomy knowledge is crucial for advancing VLLMs in hierarchical visual understanding.",
  "evaluation": "Step 1: Check for factual consistency by comparing the summaries against the source text for key points like the main findings, the role of LLMs as the bottleneck, the use of taxonomies and datasets, and the results of experiments.\nStep 2: Assess engagingness by evaluating how well the summaries convey the significance of the research, the implications for VLLM development, and the practical relevance of the findings.\nStep 3: Compare the summaries to determine which one provides a more accurate and comprehensive overview of the paper's contributions and conclusions.\n\nSummary 0 Scores:\nFactual Consistency: 3\nEngagingness: 3\n\nSummary 1 Scores:\nFactual Consistency: 3\nEngagingness: 2\n\nBest Summary: 0:\n3\n3\n0: 3\n3\n0: 3\n3\n0: 3\n3\n0: 3\n3\n0: 3\n3\n0: 3\n3\n0: 3\n3\n0: 3\n3\n0: 3\n3\n0: 3\n3\n0: 3\n3\n0: 3\n3\n0: 3\n3\n0: 3\n3\n0: 3\n3\n0",
  "tweet": "\"Vision LLMs struggle with hierarchical consistency; LLMs are the bottleneck. \ud83e\udde0\ud83d\uddbc\ufe0f\"\nOkay, let",
  "real_tweet": "\"Vision LLMs struggle with hierarchical consistency; LLMs are the bottleneck. \ud83e\udde0\ud83d\uddbc\ufe0f\"\n Link: https://arxiv.org/abs/2505.24840",
  "model_used": "Qwen/Qwen3-4B",
  "eval_mode": true
}