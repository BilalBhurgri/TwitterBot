{
  "status": "success",
  "paper_id": "2505.24849",
  "bot_num": 2,
  "processed_date": "2025-06-04T22:42:12.478623",
  "all_summaries": [
    "\"The paper investigates the statistical mechanics of extensive-width Bayesian neural networks near interpolation, analyzing a two-layer Bayesian network in the proportional regime with Gaussian inputs and teacher-student setup. Key findings include the characterization of specialisation transitions where student weights align with teacher weights, the emergence of multiple learning phases based on sample-rate alpha, and the development of a statistical mechanics framework combining replica methods and spherical integrals to predict generalisation error and free entropy. The study reveals how feature learning and alignment occur in the network, showing that specialisation transitions depend on the distribution of readouts and activation functions. The results are validated through theoretical predictions and numerical experiments, demonstrating the effectiveness of the framework in capturing the behavior of Bayesian neural networks in the extensive-width regime.\"",
    "The paper analyzes the statistical mechanics of Bayesian neural networks near interpolation, showing that in the extensive-width regime with quadratic sample sizes, feature learning occurs through specialisation transitions as the sample rate alpha increases, and derives a statistical mechanics framework to characterize prediction performance, providing insights into the behavior of Bayesian networks in the mean-field regime. The study uses a combination of replica methods and spherical integrals, and demonstrates that the generalisation error decreases as the network specialises, with specialisation transitions governed by the alignment of student weights with teacher weights, and the framework offers a quantitative description of generalisation capabilities for Bayesian shallow networks with generic activation functions."
  ],
  "best_summary_idx": 0,
  "summary": "\"The paper investigates the statistical mechanics of extensive-width Bayesian neural networks near interpolation, analyzing a two-layer Bayesian network in the proportional regime with Gaussian inputs and teacher-student setup. Key findings include the characterization of specialisation transitions where student weights align with teacher weights, the emergence of multiple learning phases based on sample-rate alpha, and the development of a statistical mechanics framework combining replica methods and spherical integrals to predict generalisation error and free entropy. The study reveals how feature learning and alignment occur in the network, showing that specialisation transitions depend on the distribution of readouts and activation functions. The results are validated through theoretical predictions and numerical experiments, demonstrating the effectiveness of the framework in capturing the behavior of Bayesian neural networks in the extensive-width regime.\"",
  "evaluation": "Step 1: Check for factual consistency by verifying that all claims in the summaries are supported by the source text.\nStep 2: Assess engagingness by evaluating how well the summaries capture the significance and novelty of the research.\nStep 3: Compare the summaries to determine which one is the most accurate and engaging.\n\nSummary 0 Score:\nFactual Consistency: 3\nEngagingness: 3\n\nSummary 1 Score:\nFactual Consistency: 3\nEngagingness: 2\n\nBest Summary: 0:\nSummary 0\nSummary 1\nBest Summary: 0: Summary 0\nSummary 1\nBest Summary: 0: Summary 0\nSummary 1\nBest Summary: 0: Summary 0\nSummary 1\nBest Summary: 0: Summary 0\nSummary 1\nBest Summary: 0: Summary 0\nSummary 1\nBest Summary: 0: Summary 0\nSummary 1\nBest Summary: 0: Summary 0\nSummary 1\nBest Summary: 0: Summary 0\nSummary 1\nBest Summary: 0: Summary 0\nSummary 1\nBest Summary: 0: Summary 0\nSummary 1\nBest Summary: 0: Summary 0\nSummary 1\nBest Summary: 0",
  "tweet": "\"So so so cool. Statistical mechanics of wide Bayesian nets near interpolation: specialisation transitions, multiple learning phases, and a new",
  "real_tweet": "\"So so so cool. Statistical mechanics of wide Bayesian nets near interpolation: specialisation transitions, multiple learning phases, and a new\n Link: https://arxiv.org/abs/2505.24849",
  "model_used": "Qwen/Qwen3-4B",
  "eval_mode": true
}