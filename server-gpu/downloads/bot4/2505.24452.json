{
  "status": "success",
  "paper_id": "2505.24452",
  "bot_num": 4,
  "processed_date": "2025-06-04T23:15:42.407064",
  "all_summaries": [
    "The paper proposes a unified learning rate schedule named Unified Budget-Aware (UBA) for budgeted-iteration training, which is theoretically grounded and outperforms existing schedules across various vision and language tasks, architectures, and training budgets. UBA is controlled by a single hyperparameter phi, which balances flexibility and simplicity, adapting to the optimization difficulty (e.g., condition number) and ensuring robust performance under fixed iteration constraints. Theoretical analysis and experiments show that UBA achieves state-of-the-art results on benchmarks, consistently outperforming baselines in accuracy and efficiency. This is a correct summary based on the paper's content. The key findings include the introduction of UBA,",
    "The paper introduces the concept of \"budgeted-iteration training,\" which focuses on achieving optimal model performance under strict iteration constraints. Existing methods for budgeted training often lack theoretical grounding and require manual tuning. The authors address these issues by developing a unified budget-aware training optimization framework that accounts for landscape curvature variations, leading to the UBA schedule. This schedule is controlled by a single hyperparameter, phi, which is theoretically connected to the condition number and optimization difficulty, enabling adaptive learning rate adjustments. Through extensive experiments"
  ],
  "best_summary_idx": 0,
  "summary": "The paper proposes a unified learning rate schedule named Unified Budget-Aware (UBA) for budgeted-iteration training, which is theoretically grounded and outperforms existing schedules across various vision and language tasks, architectures, and training budgets. UBA is controlled by a single hyperparameter phi, which balances flexibility and simplicity, adapting to the optimization difficulty (e.g., condition number) and ensuring robust performance under fixed iteration constraints. Theoretical analysis and experiments show that UBA achieves state-of-the-art results on benchmarks, consistently outperforming baselines in accuracy and efficiency. This is a correct summary based on the paper's content. The key findings include the introduction of UBA,",
  "evaluation": "Step 1: Check for factual consistency by verifying if all claims in the summaries are supported by the source text.\nStep 2: Assess engagingness by evaluating the clarity and interest level of the summaries for a general audience.\nStep 3: Compare the summaries to determine which one is the best based on the criteria.\n\nSummary 0:\nFactual Consistency: 3 (Consistent) - All claims in the summary are supported by the source text. The paper introduces UBA, explains its theoretical grounding, and presents experimental results showing its superiority over existing schedules. The role of phi and its connection to condition number are accurately described.\nEngagingness: 3 (Interesting) - The summary is clear, concise, and highlights the key contributions and results of the paper, making it accessible to a general audience.\n\nSummary 1:\nFactual Consistency: 3 (Consistent) - The summary accurately reflects the paper's main points, including the introduction of budgeted-iteration training, the development of the UBA schedule, and the theoretical and experimental validation. The role of phi and its connection to optimization difficulty are correctly described.\nEngagingness: 2 (Somewhat interesting) - While the summary is informative, it may be more engaging for those familiar with the field due to the technical terms and concepts involved.\n\nBest Summary: 0:\n3\n3\n0:\n3\n3\n0:\n3\n3\n0:\n3",
  "tweet": "\ud83d\ude80 Unified Budget-Aware (UBA) learns to adaptively balance training efficiency & accuracy across vision/linguistics",
  "real_tweet": "\ud83d\ude80 Unified Budget-Aware (UBA) learns to adaptively balance training efficiency & accuracy across vision/linguistics\n Link: https://arxiv.org/abs/2505.24452",
  "model_used": "Qwen/Qwen3-4B",
  "eval_mode": true
}