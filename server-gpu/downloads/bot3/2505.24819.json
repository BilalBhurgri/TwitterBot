{
  "status": "success",
  "paper_id": "2505.24819",
  "bot_num": 3,
  "processed_date": "2025-06-04T23:00:37.860081",
  "all_summaries": [
    "This paper proposes Bi-JCR, a framework that simultaneously performs bi-manual joint calibration and scene representation for dual manipulators with wrist-mounted cameras, eliminating the need for external calibration markers. Bi-JCR uses 3D foundation models to estimate unscaled camera poses and environment representations from images, then solves for scale, camera-extrinsics, and inter-arm relative poses through gradient descent optimization. Key findings include accurate calibration of both manipulators, metric-scale 3D environment reconstruction, and successful execution of bimanual tasks like grasping and object transfer. Evaluation against baselines shows Bi-JCR achieves lower residual errors and superior performance, particularly with DUSt3R as the 3D foundation model, and gradient descent refinement improves calibration accuracy under sparse-view conditions.",
    "This paper introduces Bi-JCR, a framework that simultaneously calibrates two manipulators with wrist-mounted cameras and constructs a metric-scale 3D representation of the environment. Bi-JCR eliminates the need for calibration markers by leveraging 3D foundation models and gradient descent optimization to recover camera extrinsics, inter-arm relative poses, and a shared, metric-consistent scene representation. Key findings show that Bi-JCR achieves accurate hand-eye calibration with low-image counts, precise scale recovery, and high-quality 3D reconstructions. The framework enables downstream bimanual tasks like grasping and object transfer, demonstrating robustness in real-world settings and superior performance compared to baseline methods such as COLMAP and Ray Diffusion. Additionally, DUSt3R performs best among 3D foundation models, and gradient descent improves calibration accuracy, especially under sparse-view conditions."
  ],
  "best_summary_idx": 1,
  "summary": "This paper introduces Bi-JCR, a framework that simultaneously calibrates two manipulators with wrist-mounted cameras and constructs a metric-scale 3D representation of the environment. Bi-JCR eliminates the need for calibration markers by leveraging 3D foundation models and gradient descent optimization to recover camera extrinsics, inter-arm relative poses, and a shared, metric-consistent scene representation. Key findings show that Bi-JCR achieves accurate hand-eye calibration with low-image counts, precise scale recovery, and high-quality 3D reconstructions. The framework enables downstream bimanual tasks like grasping and object transfer, demonstrating robustness in real-world settings and superior performance compared to baseline methods such as COLMAP and Ray Diffusion. Additionally, DUSt3R performs best among 3D foundation models, and gradient descent improves calibration accuracy, especially under sparse-view conditions.",
  "evaluation": "Step 1: Check for factual consistency by verifying if all claims in the summary are supported by the source text.\nStep 2: Assess engagingness by evaluating the summary's ability to capture the essence of the paper and its relevance to a broad audience.\nStep 3: Compare the summaries to determine which one is the best based on the evaluation criteria.\n\nFactual Consistency Scores:\nSummary 0: 3\nSummary 1: 3\n\nEngagingness Scores:\nSummary 0: 3\nSummary 1: 3\n\nBest Summary:\n1\nOkay, let's start by evaluating the factual consistency of each summary. \n\nFor Summary 0, it mentions that Bi-JCR uses 3D foundation models to estimate unscaled camera poses and environment representations from images, then solves for scale, camera-extrinsics, and inter-arm relative poses through gradient descent optimization. The source text does state that Bi-JCR uses 3D foundation models to estimate unscaled representations and camera poses, and that gradient descent is used for optimization. It also mentions that Bi-JCR eliminates the need for external markers, which is correct. The key findings like accurate calibration, metric-scale reconstruction, and successful bimanual tasks are all supported by the source text. There are no major errors here, so it's consistent.\n\nSummary 1 says Bi-JCR eliminates calibration markers by using 3D foundation models and gradient descent to recover camera extrinsics, inter-arm poses, and a shared",
  "tweet": "\ud83e\udd8b Humans have calibrated hands into 3D worlds with Bi-JCR, a butterfly of precision.\n \n\nOkay, let",
  "real_tweet": "\ud83e\udd8b Humans have calibrated hands into 3D worlds with Bi-JCR, a butterfly of precision.\n Link: https://arxiv.org/abs/2505.24819",
  "model_used": "Qwen/Qwen3-4B",
  "eval_mode": true
}