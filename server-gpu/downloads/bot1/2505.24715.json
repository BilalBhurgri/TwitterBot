{
  "status": "success",
  "paper_id": "2505.24715",
  "bot_num": 1,
  "processed_date": "2025-06-04T22:11:02.746203",
  "all_summaries": [
    "This paper proposes CoRet, a retrieval model for code editing that improves upon existing methods by optimizing for likelihood of correct code retrieval, incorporating file hierarchy and call graph contexts, leading to a 15%+ recall improvement over baselines on SWE-bench and Long Code Arena. Key findings include the effectiveness of integrating call graph neighbors and file paths, the importance of in-instance negatives in enhancing retrieval performance, and the necessity of repository-level understanding for accurate code retrieval.",
    "\"CoRet is a retrieval model for code editing that improves upon existing models by integrating file hierarchy, call graph context, and optimizing for likelihood-based retrieval. Key findings include a 15%+ recall improvement over baselines on SWE-bench and Long Code Arena, the effectiveness of in-instance negatives in enhancing retrieval performance, and the importance of file paths in capturing repository structure. The paper demonstrates that repository-level understanding is crucial for accurate code retrieval, and proposes a novel loss function and context integration approach.\""
  ],
  "best_summary_idx": 1,
  "summary": "\"CoRet is a retrieval model for code editing that improves upon existing models by integrating file hierarchy, call graph context, and optimizing for likelihood-based retrieval. Key findings include a 15%+ recall improvement over baselines on SWE-bench and Long Code Arena, the effectiveness of in-instance negatives in enhancing retrieval performance, and the importance of file paths in capturing repository structure. The paper demonstrates that repository-level understanding is crucial for accurate code retrieval, and proposes a novel loss function and context integration approach.\"",
  "evaluation": "Step 1: Check for factual consistency. Ensure that all claims in the summary are supported by the source text.\nStep 2: Assess engagingness. Determine if the summary is engaging to a general audience.\nStep 3: Compare the summaries to identify the best one based on the criteria.\n\nFactual Consistency Scores:\nSummary 0: 3\nSummary 1: 3\n\nEngagingness Scores:\nSummary 0: 3\nSummary 1: 3\n\nBest Summary:\n1\nOkay, let's go through this step by step. \n\nFirst, I need to check the factual consistency of both summaries against the source text. \n\nFor Summary 0, it mentions that CoRet improves upon existing methods by optimizing for likelihood of correct code retrieval, incorporating file hierarchy and call graph contexts, leading to a 15%+ recall improvement on SWE-bench and Long Code Arena. The source text does say that CoRet's contributions lead to improvements of at least 15 percentage points recall over the baseline methods on those datasets. It also talks about incorporating file hierarchy and call graph context, which is mentioned in the \"3.2 Call graph context\" section. The part about in-instance negatives is in the \"4.4 Results\" section, but Summary 0 doesn't mention that. However, the key points here are all covered. The summary also states that integrating call graph neighbors and file paths is effective, which is supported by the text. So",
  "tweet": "\"\ud83d\ude80 CoRet enhances code retrieval with hierarchical & contextual insights, boosting accuracy by 15%+. \ud83e\udde0 Repository structure",
  "real_tweet": "\"\ud83d\ude80 CoRet enhances code retrieval with hierarchical & contextual insights, boosting accuracy by 15%+. \ud83e\udde0 Repository structure\n Link: https://arxiv.org/abs/2505.24715",
  "model_used": "Qwen/Qwen3-4B",
  "eval_mode": true
}