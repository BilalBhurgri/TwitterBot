{
  "status": "success",
  "paper_id": "2504.04383",
  "bot_num": 0,
  "processed_date": "2025-06-05T21:45:40.419866",
  "all_summaries": [
    "This paper introduces Retro-Search, an algorithm that improves reasoning efficiency by revising reasoning trajectories to reduce unnecessary thought switches (under-thinking) and redundant steps after the correct answer is found (over-thinking). Retro-Search is effective in self-improvement and weak-to-strong revision, achieving significant performance gains and efficiency improvements in reasoning tasks, especially when applied to large-scale models like R1-671B and R1-distill models. Key findings include that retro-searched data enhances model performance, reduces response lengths, and sets new state-of-the-art results at various model sizes. The algorithm is inspired by Monte Carlo Tree Search and demonstrates superior efficiency and accuracy compared to traditional methods.",
    "This paper introduces Retro-Search, an algorithm that enhances reasoning efficiency by revising reasoning trajectories to reduce under-thinking and over-thinking. Through self-improvement and weak-to-strong revision, it improves performance and reduces inference time, achieving state-of-the-art results on math benchmarks with shorter reasoning paths. The method leverages MCTS-inspired search to refine trajectories, leading to more efficient and accurate reasoning.  "
  ],
  "best_summary_idx": 1,
  "summary": "This paper introduces Retro-Search, an algorithm that enhances reasoning efficiency by revising reasoning trajectories to reduce under-thinking and over-thinking. Through self-improvement and weak-to-strong revision, it improves performance and reduces inference time, achieving state-of-the-art results on math benchmarks with shorter reasoning paths. The method leverages MCTS-inspired search to refine trajectories, leading to more efficient and accurate reasoning.  ",
  "evaluation": "Step 1: Check for factual consistency by verifying if all claims in the summaries are supported by the source text.\nStep 2: Assess engagingness by evaluating how well the summaries capture the novelty and significance of the research.\nStep 3: Compare the summaries to determine which one is the most accurate and engaging.\n\nSummary 0 scores:\nFactual Consistency: 2\nEngagingness: 3\n\nSummary 1 scores:\nFactual Consistency: 3\nEngagingness: 2\n\nBest Summary: 1\nOkay, let's start by evaluating the factual consistency of each summary based on the source text.\n\nFor Summary 0, it mentions that Retro-Search is inspired by Monte Carlo Tree Search (MCTS) and that it reduces under-thinking and over-thinking. The source text does state that Retro-Search is inspired by MCTS and that it addresses under-thinking and over-thinking. However, it also mentions that the algorithm is used for self-improvement and weak-to-strong revision, which is supported. The summary correctly states that it achieves state-of-the-art results on math benchmarks with shorter reasoning paths. However, the source text does not explicitly mention \"state-of-the-art results on math benchmarks\" but does mention setting new state-of-the-art performance. So this might be a minor inaccuracy. Overall, it seems consistent except for that point, so a score of 2 for factual consistency.\n\nFor Summary 1, it correctly states that Retro-Search",
  "tweet": "\"Retro-Search \ud83e\udde0 boosts reasoning speed & accuracy via trajectory refinement, cutting inference time for math tasks. #AI",
  "real_tweet": "\"Retro-Search \ud83e\udde0 boosts reasoning speed & accuracy via trajectory refinement, cutting inference time for math tasks. #AI\n Link: https://arxiv.org/abs/2504.04383",
  "model_used": "Qwen/Qwen3-4B",
  "eval_mode": true
}