{
  "status": "success",
  "paper_id": "2505.17968",
  "bot_num": 0,
  "processed_date": "2025-06-05T21:20:17.791536",
  "all_summaries": [
    "This paper investigates the reliability of large language models (LLMs) as AI scientists by assessing their ability to reverse-engineer black-box systems. The authors introduce three tasks inspired by cognitive science: reconstructing list-mapping programs, formal languages, and math equations. They evaluate LLMs on these tasks under observation-only and observation-intervention scenarios. Findings show that LLMs struggle with inductive reasoning from passive observations, peaking at 10 observations, and benefit significantly from active interventions that help mitigate overcomplication and overlooking failure modes. Interventions enable LLMs to refine hypotheses and improve performance, though the effectiveness of intervention data varies. The study highlights the importance of active learning and identifies limitations in transferring knowledge between LLMs. Overall, LLMs fall short of Bayesian models in reverse-engineering, emphasizing the need for improved methods to enhance their scientific reasoning capabilities.",
    "This paper investigates the capabilities of large language models (LLMs) in reverse-engineering black-box systems, focusing on their ability to infer underlying mechanisms from passive observations and actively collect data through interventions. The authors designed three black-box tasks inspired by cognitive science: list-mapping programs, formal languages, and math equations. They evaluated LLMs on these tasks, revealing that while LLMs struggle to infer mechanisms from passive data alone, allowing them to perform interventions significantly improves performance by mitigating failure modes such as overcomplication and overlooking. However, the benefits of interventions are limited when the data is reused across different LLMs, suggesting that intervention data is most useful for the model that generated it. The study also connects LLMs' reverse-engineering abilities to concepts in reinforcement learning and cognitive science, highlighting the importance of active learning in scientific discovery."
  ],
  "best_summary_idx": 1,
  "summary": "This paper investigates the capabilities of large language models (LLMs) in reverse-engineering black-box systems, focusing on their ability to infer underlying mechanisms from passive observations and actively collect data through interventions. The authors designed three black-box tasks inspired by cognitive science: list-mapping programs, formal languages, and math equations. They evaluated LLMs on these tasks, revealing that while LLMs struggle to infer mechanisms from passive data alone, allowing them to perform interventions significantly improves performance by mitigating failure modes such as overcomplication and overlooking. However, the benefits of interventions are limited when the data is reused across different LLMs, suggesting that intervention data is most useful for the model that generated it. The study also connects LLMs' reverse-engineering abilities to concepts in reinforcement learning and cognitive science, highlighting the importance of active learning in scientific discovery.",
  "evaluation": "Step 1: Check for factual consistency by verifying that all claims in the summaries are supported by the source text.\nStep 2: Assess engagingness by determining if the summaries are accessible and interesting to a general audience.\nStep 3: Compare the summaries to identify which one best captures the key findings and contributions of the paper.\n\nFactual Consistency Scores:\nSummary 0: 3\nSummary 1: 3\n\nEngagingness Scores:\nSummary 0: 3\nSummary 1: 3\n\nBest Summary:\n1\nOkay, let's see. I need to evaluate the two summaries based on the given criteria. \n\nFirst, for factual consistency. Both summaries mention the three tasks (list-mapping programs, formal languages, math equations) which are in the source text. They talk about LLMs struggling with passive observations and improving with interventions, which matches the paper's findings. The part about interventions helping with overcomplication and overlooking is also correct. The summaries also mention the connection to reinforcement learning and cognitive science, which the source text does discuss. The only thing I need to check is if there are any major errors. Both summaries seem to align with the paper's content without major inaccuracies. So both get a 3 for factual consistency.\n\nNext, engagingness. Summary 0 uses more technical terms but explains the key points clearly. Summary 1 is more concise and mentions the connection to reinforcement learning and cognitive science, which might be more engaging for",
  "tweet": "\"Large LLMs excel at reverse-engineering black-box systems via interventions, enhancing understanding but limited across models. \ud83e\udde0",
  "real_tweet": "\"Large LLMs excel at reverse-engineering black-box systems via interventions, enhancing understanding but limited across models. \ud83e\udde0\n Link: https://arxiv.org/abs/2505.17968",
  "model_used": "Qwen/Qwen3-4B",
  "eval_mode": true
}