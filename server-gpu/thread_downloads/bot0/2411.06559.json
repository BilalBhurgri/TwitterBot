{
  "status": "success",
  "paper_id": "2411.06559",
  "bot_num": 0,
  "processed_date": "2025-06-05T21:48:51.057366",
  "all_summaries": [
    "This paper proposes a model-based planning framework called WEBDREAMER that leverages large language models (LLMs) to simulate web environments and enable efficient planning for web agents. The framework combines LLMs for simulating state transitions and scoring future states, allowing the agent to make informed decisions without extensive real-world interactions. The paper also introduces a world model, Dreamer-7B, trained on 3.1 million synthesized web interaction data, which achieves performance comparable to state-of-the-art LLMs like GPT-4o on multiple benchmarks. Experimental results show that WEBDREAMER outperforms reactive baselines and tree search methods in efficiency and effectiveness, particularly on real-world websites. The study highlights the potential of using LLMs for model-based planning in complex web environments, establishing a practical foundation for building world models through data synthesis, training, and evaluation.",
    "This paper proposes WEBDREAMER, a model-based planning framework that leverages large language models (LLMs) to simulate and score possible future states in web environments, significantly improving performance over reactive baselines and tree search methods on benchmarks like VisualWebArena and Mind2Web-Live. It introduces Dreamer-7B, a world model trained on synthesized data, which achieves performance comparable to GPT-4o and outperforms it in some scenarios through domain-specific fine-tuning. The framework addresses challenges in real-world web navigation by using LLMs to simulate actions and avoid irreversible changes, enhancing efficiency and decision-making capabilities. Key contributions include the development of a scalable data synthesis pipeline, the creation of a world model, and empirical validation of the effectiveness of LLM-based planning in complex web tasks."
  ],
  "best_summary_idx": 0,
  "summary": "This paper proposes a model-based planning framework called WEBDREAMER that leverages large language models (LLMs) to simulate web environments and enable efficient planning for web agents. The framework combines LLMs for simulating state transitions and scoring future states, allowing the agent to make informed decisions without extensive real-world interactions. The paper also introduces a world model, Dreamer-7B, trained on 3.1 million synthesized web interaction data, which achieves performance comparable to state-of-the-art LLMs like GPT-4o on multiple benchmarks. Experimental results show that WEBDREAMER outperforms reactive baselines and tree search methods in efficiency and effectiveness, particularly on real-world websites. The study highlights the potential of using LLMs for model-based planning in complex web environments, establishing a practical foundation for building world models through data synthesis, training, and evaluation.",
  "evaluation": "Step 1: Check for factual consistency by verifying if all claims in the summaries are supported by the source text.\nStep 2: Assess engagingness by evaluating the clarity and interest level of the summaries for a general audience.\nStep 3: Compare the summaries to determine which one is the best based on the criteria.\n\nSummary 0 Factual Consistency: 3 (Consistent)\nSummary 1 Factual Consistency: 3 (Consistent)\n\nSummary 0 Engagingness: 3 (Interesting)\nSummary 1 Engagingness: 2 (Somewhat interesting)\n\nBest Summary: 0\nOkay, let's go through the evaluation steps as outlined.\n\n**Step 1: Factual Consistency Check**\nBoth summaries accurately reflect the content of the source text. Summary 0 mentions the framework WEBDREAMER, the use of LLMs for simulation, the Dreamer-7B model, and the experimental results. Summary 1 also covers these points, including the benchmarks, performance comparisons, and the data synthesis pipeline. Both summaries correctly state that WEBDREAMER outperforms reactive baselines and tree search methods, and that Dreamer-7B is comparable to GPT-4o. There are no major errors or unsupported claims in either summary. Therefore, both summaries have a factual consistency score of 3.\n\n**Step 2: Engagingness Assessment**\nSummary 0 is more engaging as it presents the information in a clear and concise manner",
  "tweet": "\"\ud83d\ude80 A groundbreaking model-based planning framework, **WEBDREAMER**, uses LLMs to simulate web environments and improve decision",
  "real_tweet": "\"\ud83d\ude80 A groundbreaking model-based planning framework, **WEBDREAMER**, uses LLMs to simulate web environments and improve decision\n Link: https://arxiv.org/abs/2411.06559",
  "model_used": "Qwen/Qwen3-4B",
  "eval_mode": true
}