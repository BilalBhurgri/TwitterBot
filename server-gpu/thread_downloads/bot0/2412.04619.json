{
  "status": "success",
  "paper_id": "2412.04619",
  "bot_num": 0,
  "processed_date": "2025-06-05T21:28:09.647597",
  "all_summaries": [
    "This paper investigates how data characteristics influence language model generalization, finding that center-embeddings drive hierarchical syntactic generalization, while data diversity and complexity determine rule preferences and training stability. Models trained on data with high complexity (center-embeddings) generalize better to out-of-distribution (OOD) data, but unstable training dynamics arise when data mixes complex and simple structures. The study reveals that consistent OOD generalization requires committing to a systematic rule (either linear or hierarchical), and that intermediate levels of data diversity lead to unstable training and inconsistent behavior across random seeds. Additionally, the paper demonstrates that data diversity promotes systematic generalization over memorization, highlighting the critical role of data composition in shaping model behavior and generalization.",
    "The paper explores how data characteristics influence language models' generalization behaviors and training stability, finding that center-embedded sentences drive hierarchical generalization, while mixed data leads to unstable OOD performance. It demonstrates that models stabilize in OOD performance only when committed to a systematic rule, and that data diversity and complexity determine rule preference. The study reveals that data composition critically shapes models' ability to generalize beyond training data, highlighting the importance of data structure in guiding generalization and training dynamics."
  ],
  "best_summary_idx": 0,
  "summary": "This paper investigates how data characteristics influence language model generalization, finding that center-embeddings drive hierarchical syntactic generalization, while data diversity and complexity determine rule preferences and training stability. Models trained on data with high complexity (center-embeddings) generalize better to out-of-distribution (OOD) data, but unstable training dynamics arise when data mixes complex and simple structures. The study reveals that consistent OOD generalization requires committing to a systematic rule (either linear or hierarchical), and that intermediate levels of data diversity lead to unstable training and inconsistent behavior across random seeds. Additionally, the paper demonstrates that data diversity promotes systematic generalization over memorization, highlighting the critical role of data composition in shaping model behavior and generalization.",
  "evaluation": "Step 1: Check for factual consistency by verifying if all claims in the summaries are supported by the source text.\nStep 2: Assess engagingness by evaluating how well the summaries capture the key findings and their relevance to a general audience.\nStep 3: Compare the summaries to determine which one is the best based on the evaluation criteria.\n\nSummary 0 Factual Consistency: 3\nSummary 1 Factual Consistency: 3\nSummary 0 Engagingness: 3\nSummary 1 Engagingness: 2\nBest Summary: 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "tweet": "\"\ud83d\ude80 Data diversity drives systematic generalization in models. \ud83e\udde0 Consistent rules emerge from structured data. \ud83d\udd0d Study shows",
  "real_tweet": "\"\ud83d\ude80 Data diversity drives systematic generalization in models. \ud83e\udde0 Consistent rules emerge from structured data. \ud83d\udd0d Study shows\n Link: https://arxiv.org/abs/2412.04619",
  "model_used": "Qwen/Qwen3-4B",
  "eval_mode": true
}