{
  "status": "success",
  "paper_id": "2410.02683",
  "bot_num": 0,
  "processed_date": "2025-06-05T21:03:38.761624",
  "all_summaries": [
    "This paper introduces DAILYDILEMMAS, a dataset of 1,360 everyday moral dilemmas designed to explore how large language models (LLMs) prioritize values in complex, real-world decisions. The dataset includes 301 human values mapped to five theoretical frameworks: World Value Survey, Moral Foundations Theory, Maslow's Hierarchy of Needs, Aristotle's Virtues, and Plutchik's Wheel of Emotions. The paper evaluates LLMs' value preferences, revealing inconsistencies in their alignment with principles like OpenAI's ModelSpec and Anthropic's Constitutional AI, and highlights challenges in steering LLMs to prioritize specific values in ethical dilemmas. Key findings include LLMs' general preference for fairness, truthfulness, and care, along with variations in their handling of conflicting values, and the difficulty of aligning models with human preferences through user instructions.",
    "This paper introduces DAILYDILEMMAS, a dataset of 1,360 daily-life moral dilemmas designed to explore how large language models (LLMs) prioritize values in complex, ambiguous real-world scenarios. The dataset includes 301 human values mapped across five theoretical frameworks: World Value Survey, Moral Foundations Theory, Maslow's Hierarchy of Needs, Aristotle's Virtues, and Plutchik's Wheel of Emotions. The paper analyzes how LLMs like GPT-4-turbo and Claude-3-Haiku align with or deviate from their stated principles, revealing inconsistencies in their value preferences, particularly in balancing self-expression versus survival, fairness, and safety. The study validates the dataset\u2019s realism through comparisons with human-annotated dilemmas from Reddit, demonstrating that generated dilemmas reflect real-world moral intuitions. The findings highlight challenges in aligning LLMs with human values in complex ethical decisions."
  ],
  "best_summary_idx": 1,
  "summary": "This paper introduces DAILYDILEMMAS, a dataset of 1,360 daily-life moral dilemmas designed to explore how large language models (LLMs) prioritize values in complex, ambiguous real-world scenarios. The dataset includes 301 human values mapped across five theoretical frameworks: World Value Survey, Moral Foundations Theory, Maslow's Hierarchy of Needs, Aristotle's Virtues, and Plutchik's Wheel of Emotions. The paper analyzes how LLMs like GPT-4-turbo and Claude-3-Haiku align with or deviate from their stated principles, revealing inconsistencies in their value preferences, particularly in balancing self-expression versus survival, fairness, and safety. The study validates the dataset\u2019s realism through comparisons with human-annotated dilemmas from Reddit, demonstrating that generated dilemmas reflect real-world moral intuitions. The findings highlight challenges in aligning LLMs with human values in complex ethical decisions.",
  "evaluation": "Step 1: Check for factual consistency by verifying that all claims in the summary are directly supported by the source text.\nStep 2: Assess engagingness by determining if the summary is accessible and interesting to a general audience.\nStep 3: Compare the summaries to identify which one best captures the essence of the paper and is most effective in communicating its key findings.\n\nSummary 0 Scores:\nFactual Consistency: 3\nEngagingness: 3\n\nSummary 1 Scores:\nFactual Consistency: 3\nEngagingness: 3\n\nBest Summary: 1:\nSummary 0\nSummary 1\nBest Summary: 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary 1:\nSummary",
  "tweet": "Drum roll \ud83e\udd41 DAILYDILEMMAS dataset reveals LLMs' value conflicts in real-world ethics.",
  "real_tweet": "Drum roll \ud83e\udd41 DAILYDILEMMAS dataset reveals LLMs' value conflicts in real-world ethics.\n Link: https://arxiv.org/abs/2410.02683",
  "model_used": "Qwen/Qwen3-4B",
  "eval_mode": true
}