{
  "status": "success",
  "paper_id": "2504.11900",
  "bot_num": 1,
  "processed_date": "2025-06-05T22:19:45.221611",
  "all_summaries": [
    "The paper proposes FLAWEDFICTIONSMAKER, an algorithm to generate plot holes in stories, and constructs a benchmark called FLAWEDFICTIONS for evaluating LLM reasoning through tasks like classifying and localizing plot holes. It shows that leading LLMs struggle with detecting plot holes, particularly in longer stories, and emphasizes the importance of narrative consistency in LLM-generated content, revealing significant gaps in their ability to understand deep narrative structures. The study also finds that LLMs often misinterpret characters' motivations or behavior, track entities' states incorrectly, or misinterpret established rules, leading to frequent false positives in detecting plot holes.",
    "First, the paper introduces FLAWEDFICTIONSMAKER, an algorithm to generate plot holes in stories. They created a benchmark called FLAWEDFICTIONS to evaluate LLMs' ability to detect plot holes. The study found that even advanced models like GPT-4o, o3-mini, and Llama-3.3-70B struggled with this task, especially as story length increased. Longer stories (FLAWEDFICTIONSLONG) were particularly challenging, with models performing close to random. The paper also highlights that LLMs often misinterpret character motivations, track entities incorrectly, or misunderstand genre conventions, leading to false positives. They tested LLM-generated stories and found higher continuity errors compared to human-written ones. The study emphasizes the need for better reasoning frameworks and datasets to address these gaps in LLM narrative understanding. "
  ],
  "best_summary_idx": 0,
  "summary": "The paper proposes FLAWEDFICTIONSMAKER, an algorithm to generate plot holes in stories, and constructs a benchmark called FLAWEDFICTIONS for evaluating LLM reasoning through tasks like classifying and localizing plot holes. It shows that leading LLMs struggle with detecting plot holes, particularly in longer stories, and emphasizes the importance of narrative consistency in LLM-generated content, revealing significant gaps in their ability to understand deep narrative structures. The study also finds that LLMs often misinterpret characters' motivations or behavior, track entities' states incorrectly, or misinterpret established rules, leading to frequent false positives in detecting plot holes.",
  "evaluation": "- Check for factual consistency by comparing the summaries to the source text.\n- Assess the engagingness by evaluating the summaries' ability to capture the study's significance and key findings.\n- Determine which summary best represents the study's main points and is most accessible to a general audience.\n\nSummary 0 Factual Consistency: 3 (Consistent)\nSummary 0 Engagingness: 3 (Interesting)\nSummary 1 Factual Consistency: 3 (Consistent)\nSummary 1 Engagingness: 2 (Somewhat interesting)\n\nBest Summary: 0\nOkay, I need to evaluate the two summaries provided based on the given criteria. Let's start with the first summary, Summary 0. \n\nFirst, checking factual consistency. The summary mentions FLAWEDFICTIONSMAKER, the benchmark FLAWEDFICTIONS, and the findings that leading LLMs struggle with detecting plot holes, especially in longer stories. It also notes that LLMs often misinterpret character motivations, track entities incorrectly, or misunderstand genre conventions, leading to false positives. The study also found higher continuity errors in LLM-generated stories compared to human-written ones. These points are all supported by the source text, so the factual consistency is 3 (Consistent).\n\nNext, engagingness. The summary is clear and concise, highlighting the main contributions of the paper: the algorithm, the benchmark, the findings on LLM performance, and the implications for narrative understanding. It's written in a way",
  "tweet": "\"LLMs struggle with detecting plot holes, especially in long stories. \ud83e\udde9\ud83d\udcd6\"\nOkay, let's break down the",
  "real_tweet": "\"LLMs struggle with detecting plot holes, especially in long stories. \ud83e\udde9\ud83d\udcd6\"\n Link: https://arxiv.org/abs/2504.11900",
  "model_used": "Qwen/Qwen3-4B",
  "eval_mode": true
}