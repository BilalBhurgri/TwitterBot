{
  "thread": [
    "Researchers reveal LLMs make unrealistic assumptions about human rationality leading biases \ud83e\udd16\ud83d\udca1 #ArtificialIntelligenceBias\n Link: https://arxiv.org/abs/2406.17055",
    "Researchers evaluate LLMs' predictive abilities through forward & reverse decision-making tests \ud83e\udd16\ud83d\udca1 #ArtificialIntelligenceResearch",
    "LLMs may overestimate humans' rationality due to CoT prompting methods used \ud83d\udca1\ud83d\udcca #ArtificialIntelligence",
    "LLMs show surprising similarities to human thought processes in inference tasks \ud83e\udd16\ud83d\udca1 #ArtificialIntelligence",
    "Researchers separate AI goals into aligning with humans' intentions & actions now \ud83e\udd16\ud83d\udca1 #ArtificialIntelligence",
    "Current large language models struggle mimicking humans' complex decision-making processes effectively \ud83d\udca1\ud83e\udd16 #ArtificialIntelligenceLimitations",
    "Researchers reveal groundbreaking advancements in transformer models for natural language processing \ud83d\udcbb\ud83d\udd0d #DeepLearningTrends"
  ]
}